# Human_Action_Recognition
딥러닝 기반 사람 행동 인식 시스템.
동영상 파일 또는 실시간 웹캠 입력을 분석해 사람이 어떤 행동을 하고 있는지 자동으로 예측한다.
ResNet18 + LSTM 구조로 시간 흐름 정보까지 반영해 행동을 분류한다. 실시간 모드에서는 YOLO로 사람 박스를 감지하고 추적한다.

----------------------------------------------------------------------------------------------------------------------------------------------------------------

1 프로젝트 개요

- 데이터셋(5개 행동 클래스)을 기반으로, 동영상 또는 실시간 웹캠 영상에서 사람의 행동을 자동 분류하는 딥러닝 모델을 구현한 프로젝트입니다.

- 단일 프레임 이미지가 아닌 프레임 시퀀스의 시간 흐름을 학습하여 행동을 이해하기 위해
ResNet18 기반 Spatial Feature Extractor + LSTM Temporal Model 구조를 적용했으며,
실시간 감지 모드에서는 YOLO를 이용해 사람 영역을 탐지하고 인식 안정성을 높였습니다.

- End-to-End 구성
전처리 → 프레임 추출 → 데이터 증강 → 모델 학습 → 추론(Top-K) → 실시간 인식까지 모두 포함된 완전한 파이프라인

----------------------------------------------------------------------------------------------------------------------------------------------------------------

2. 모델 구조(ResNet18 + LSTM)

- ResNet18:
동영상의 각 프레임을 보고 중요한 특징만 뽑아내는 역할.
(예: 라켓을 든 손, 팔의 각도, 몸의 방향 같은 핵심 정보만 숫자로 추림)
→ 한 프레임당 512개 숫자의 벡터로 요약함.

- LSTM:
이 프레임들이 시간에 따라 어떻게 변하는지를 이해하는 역할.

- PackedSequence:
동영상마다 프레임 길이가 다 다르기 때문에, 쓸데없이 빈 프레임까지 계산하지 않도록 효율적으로 필요한 길이만 처리하려고 사용하는 방식.

- LSTM이 본 최종 결과를 Fully Connected Layer로 넘기고 행동별 확률 계산 (Softmax) 확률이 가장 높은 Top-K 행동을 출력

- YOLO: 화면에서 사람 위치를 찾는 역할 → "사람 박스"만 잘라서 모델에 전달 (배경 잡음 제거)

- 프레임 버퍼 : 최신 20장 정도를 계속 쌓아서, 순간 포즈가 아니라 동작 전체를 보고 판단

----------------------------------------------------------------------------------------------------------------------------------------------------------------

3. 학습 방식 (쉽게 설명)

- Loss 정답 데이터가 불완전해도 학습하도록 완화

- Optimizer : ResNet은 천천히, LSTM은 빠르게 학습시키는 방식

- Scheduler : 학습이 정체되면 자동으로 속도 줄이기

- Dropout : 과적합 방지 (쓸데없이 외우는 거 방지)

- Gradient clipping : 폭발적인 gradient 방지 (학습 안정화)

- Early Stopping  : 더 이상 좋아지지 않으면 훈련 종료

- Metrics Accuracy / Confusion Matrix : 정확도 + 어떤 행동을 헷갈리는지 시각화

----------------------------------------------------------------------------------------------------------------------------------------------------------------

4.기능 개요

- 동영상 파일 분석 입력 영상에서 Top-K 행동 예측

- 실시간 웹캠 감지 YOLO 감지 + 프레임 기반 행동 분류

- 시각화 Bounding box + 확률 그래프

- GUI Tkinter 파일 선택 UI

- 예측 출력 확률 내림차순 Top-K 표시

----------------------------------------------------------------------------------------------------------------------------------------------------------------

5. 기술 스택(딥러닝)

PyTorch, OpenCV, Tkinter, Matplotlib

Albumentations Data Augmentation

Ultralytics YOLO, ResNet18(backbone), LSTM(sequence model)

----------------------------------------------------------------------------------------------------------------------------------------------------------------
<img width="961" height="677" alt="opencv3" src="https://github.com/user-attachments/assets/a48ededa-9dfa-4cfa-9ce8-2ccf80d13cab" />

이미지를 프레임으로 학습중인 과정

<img width="1056" height="639" alt="opencv" src="https://github.com/user-attachments/assets/7b4a4256-33e2-45db-b99d-55b87181b951" />
<img width="394" height="147" alt="o1pencv" src="https://github.com/user-attachments/assets/75bc09f5-5d7d-4968-9236-5b500b280893" />

학습한 데이터를 바탕으로 영상의 객체가 어떤 행동인지 탐지 후 출력

